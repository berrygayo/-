{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.5뉴스기사분류:다중분류문제.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPjROZaHWPh+IEyeREtI9Qv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berrygayo/Deep-learning-to-learn-from-the-founder-of-Keras/blob/master/3_5%EB%89%B4%EC%8A%A4%EA%B8%B0%EC%82%AC%EB%B6%84%EB%A5%98_%EB%8B%A4%EC%A4%91%EB%B6%84%EB%A5%98%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDt4CYo_J1RH"
      },
      "source": [
        "# 3.5 뉴스 기사 분류 : 다중 분류 문제(multiclass classifiacation)\r\n",
        "+ 로이터(Reuter) 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망 \r\n",
        "+ 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제(single-label, multiclass claddification)이다.\r\n",
        "+ 각 데이터 포인트가 여러 개의 범주(예를들어 토픽)에 속할 수 있다면 이것은 다중 레이블 다중 분류(multi-label, multiclass classification) 문제이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHI2hbtHK8di"
      },
      "source": [
        "## 3.5.1 로이터 데이터 셋 \r\n",
        "+ 1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합 \r\n",
        "46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다. \r\n",
        "IMDB, MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3k6xqapLTbd"
      },
      "source": [
        "from keras.datasets import reuters\r\n",
        "(train_data, train_labels), (test_data, test_labels)=reuters.load_data(num_words=10000) #데이터에서 가장 자주 등장하는 단어 1만개로 제한 \r\n",
        "# 여기에는 8982개의 훈련 샘플과 2246개의 테스트 샘플이 있다 ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENt8N1tTNfSg"
      },
      "source": [
        "# 여기에는 8982개의 훈련 샘플과 2246개의 테스트 샘플이 있다 .\r\n",
        "len(train_data)\r\n",
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngPG3nFaK8-R"
      },
      "source": [
        "# 각 샘플은 정수 리스트입니다(단어인덱스)\r\n",
        "train_data[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsLfyu1vK9Al"
      },
      "source": [
        "word_index=reuters.get_word_index()\r\n",
        "reverse_word_index=dict([(value,key) for (key,value) in word_index.items()])\r\n",
        "decoded_newswire=' '.join([reverse_word_index.get(i-3,'?') for i in train_data[0]]) #0,1,2는 '패딩','문서 시작','사전에 없음'을 위한 인덱스이므로 3을 뺍니다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ALXX__VRM26"
      },
      "source": [
        "word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVPBmP4VK9DD"
      },
      "source": [
        "reverse_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdix0NtFTdla"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2vPwv8cK9Ff"
      },
      "source": [
        "decoded_newswire"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A5x3yIJK9IH"
      },
      "source": [
        "## 3.5.2 데이터 준비 \r\n",
        "\r\n",
        "### 데이터 > 벡터로 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZWDLERYXTkn"
      },
      "source": [
        "import numpy as np \r\n",
        "\r\n",
        "def vectorize_sequences(sequences,dimension=10000):\r\n",
        "    results=np.zeros((len(sequences), dimension))\r\n",
        "    for i, sequence in enumerate(sequences):\r\n",
        "        results[i,sequence]=1.\r\n",
        "    return results \r\n",
        "\r\n",
        "x_train=vectorize_sequences(train_data)\r\n",
        "x_test=vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBcp3PvQXTnO"
      },
      "source": [
        "np.zeros((3,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcyR0XBL2jUh"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2KHOoUAXTpU"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d746SHNU_YQ9"
      },
      "source": [
        "### 레이블 > 벡터로 \r\n",
        "+ 레이블의 리스트를 정수 텐서로 변환 \r\n",
        "+ 원-핫 인코딩을 사용하는 것 \r\n",
        "\r\n",
        "원-핫 인코딩이 범주형 데이터에 널ㄹ ㅣ사용되기 때문에 범주형 인코딩(categorical encoding)이라고도 부릅니다. 원-랏 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLcDihF-_YTX"
      },
      "source": [
        "## 원핫 인코딩 코드 \r\n",
        "def to_one_hot(labels, dimension=46):\r\n",
        "    results=np.zeros((len(labels),dimension))\r\n",
        "    for i, label in enumerate(labels):\r\n",
        "        results[i,label]=1.\r\n",
        "    return results \r\n",
        "\r\n",
        "one_hot_train_labels=to_one_hot(train_labels)\r\n",
        "one_hot_test_labels=to_one_hot(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6veMNRGS_YVh"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCsUb1hS_gwM"
      },
      "source": [
        "one_hot_train_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGPvbtlw_rTk"
      },
      "source": [
        "keras에는 이를 위한 내장 함수가 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILjKRn0R_uoq"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\r\n",
        "\r\n",
        "one_hot_train_labels=to_categorical(train_labels)\r\n",
        "one_hot_test_labels=to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-nm9hcj_uqz"
      },
      "source": [
        "## 3.5.3 모델 구성 \r\n",
        "이전 영화 리뷰 분류 문제와 비슷해보이지만, 출력 클래스의 개수가 2개에서 46개로 늘었다. (출력 공간의 차원이 훨씬 커졌다.)\r\n",
        "이전에 사용했던 것처럼 Dense 층을 쌓으면 각  층은 이전 층의 출력에서 제공한 정보만 사용할 수 없다. \r\n",
        "한 층이 분류 문제에 필요한 일부 정보를 누락하면 그다음 층에서 이를 복할 방법이 없습니다. \r\n",
        "각 층은 잠재적으로 정보의 병목(information bottleneck)이 될 수 있습니다.\r\n",
        "이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약되는것이 많을 것 같습니다.\r\n",
        "이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다. \r\n",
        "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다 > 64개의 유닛 사용 \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNGf6TuRBUZY"
      },
      "source": [
        "> 정보의 병목이 무엇인가? information bottleneck\r\n",
        "\r\n",
        "좁은 병 입구에 대량의 물을 집어 넣음 \r\n",
        "\r\n",
        " 전체 시스템의 성능이나 용량이 하나의 구성 요소로 인해 제한을 받는 현상을 말한다.  > 시스템에서의 병목현상 \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWYwaGBYCZo_"
      },
      "source": [
        "from keras import models \r\n",
        "from keras import layers \r\n",
        "\r\n",
        "model=models.Sequential()\r\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(64,activation='relu'))\r\n",
        "model.add(layers.Dense(46,activation='softmax'))\r\n",
        "\r\n",
        "# softmax 활성화 함수 > 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력한다. \r\n",
        "# 즉 46차원의 출력 벡터를 만들어 output[i]는 어떤 샘플이 클래스 i에 속할 확률이다. 46개의 값을 모두 더하면 1이 된다. \r\n",
        "\r\n",
        "# 이진분류 > sigmoid, 다중분류 > softmax "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFClEvC0C_qz"
      },
      "source": [
        "# 이런 문제에 사용할 최선의 손실 함수는 categorical_crossentropy입니다. 이 함수는 두 확률 분포 사이의 거리르 ㄹ측정합니다. \r\n",
        "# 여기서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리 \r\n",
        "# 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련한다\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fPNks-8FZsZ"
      },
      "source": [
        "## 3.5.4 훈련 검증 \r\n",
        "훈련 데이터에서 1000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izU9E5y3FXug"
      },
      "source": [
        "x_val=x_train[:1000]\r\n",
        "partial_x_train=x_train[1000:]\r\n",
        "\r\n",
        "y_val=one_hot_train_labels[:1000]\r\n",
        "partial_y_train=one_hot_train_labels[1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYBdqjP8CX_3"
      },
      "source": [
        "# 20번의 에포크로 모델을 훈련시킨다.\r\n",
        "history=model.fit(partial_x_train, \r\n",
        "                  partial_y_train,\r\n",
        "                  epochs=20,\r\n",
        "                  batch_size=512,\r\n",
        "                  validation_data=(x_val,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouc3KqcSGDcA"
      },
      "source": [
        "# 훈련과 검증 손실 그리기 \r\n",
        "import matplotlib.pyplot as plt \r\n",
        "\r\n",
        "loss=history.history['loss']\r\n",
        "val_loss=history.history['val_loss']\r\n",
        "\r\n",
        "epochs=range(1,len(loss)+1)\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf2d4arMHbBS"
      },
      "source": [
        "plt.clf() #그래프를 초기화 \r\n",
        "\r\n",
        "acc=history.history['accuracy']\r\n",
        "val_acc=history.history['val_accuracy']\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\r\n",
        "plt.title('Training and validation acc')\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6wKBMuaHhjO"
      },
      "source": [
        "### 이 모델은 아홉 번째 에포트 이후에 과대적합이 시작됩니다. 아홉 번째 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYycH-EACVYC"
      },
      "source": [
        "from keras import models \r\n",
        "from keras import layers \r\n",
        "\r\n",
        "model=models.Sequential()\r\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(64,activation='relu'))\r\n",
        "model.add(layers.Dense(46,activation='softmax'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(partial_x_train, \r\n",
        "                  partial_y_train,\r\n",
        "                  epochs=9,#9번 학습으로 변경 \r\n",
        "                  batch_size=512,\r\n",
        "                  validation_data=(x_val,y_val))\r\n",
        "\r\n",
        "results=model.evaluate(x_test,one_hot_test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAg5YP4nITv4"
      },
      "source": [
        "# 최종 결과는 다음과 같다 \r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJAozbExIYXF"
      },
      "source": [
        "### 대략 78%의 정확도를 달성. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 18% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIj4pHtn_utH"
      },
      "source": [
        "import copy \r\n",
        "test_labels_copy=copy.copy(test_labels)\r\n",
        "np.random.shuffle(test_labels_copy)\r\n",
        "hits_array=np.array(test_labels)==np.array(test_labels_copy)\r\n",
        "float(np.sum(hits_array))/len(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TriLiy-WI9U1"
      },
      "source": [
        "test_labels # 진짜 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCfe-k4GI7lv"
      },
      "source": [
        "test_labels_copy #랜덤으로 섞음 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imkeSv-eJX3y"
      },
      "source": [
        "# 3.5.5 새로운 데이터에 대해 예측하기 \r\n",
        "모델 객체의 predict 메서드는 46개의 토픽에 대한 확률 분포를 반환합니다.\r\n",
        "테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mko_WnB3JhAO"
      },
      "source": [
        "predictions=model.predict(x_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p32z9HQJkh-"
      },
      "source": [
        "predictions[0].shape # 각 항목은 길이가 46인 벡터이다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQi6BDiQJX59"
      },
      "source": [
        "np.sum(predictions[0]) #이 벡터의 원소 합은 1이다 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0UH97CuJX8g"
      },
      "source": [
        "np.argmax(predictions[0]) # 가장 높은 확률이 예측 클라스가 됨 > 4 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x1UcE6wJ8y8"
      },
      "source": [
        "# 3.5.6 레이블과 손실을 다루는 다른 방법\r\n",
        "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAIWnijUJ81Z"
      },
      "source": [
        "y_train=np.array(train_labels)\r\n",
        "y_test=np.array(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0lTvHc3KPpq"
      },
      "source": [
        "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 앞서 사용한 categorical_crossentropy는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 sparse_categorical_crossentripy를 사용해야합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gs-amo9J886"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='sparse_categorical_crossentropy',\r\n",
        "              metrics=['acc'])\r\n",
        "\r\n",
        "# 이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 categorical_crossentropy 와 동일합니다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fNRnsLIKvwE"
      },
      "source": [
        "# 3.5.7 충분히 큰 중간층을 두어야 하는 이유 \r\n",
        "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를들어 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLY_hGo4LFGj"
      },
      "source": [
        "model=models.Sequential()\r\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(4,activation='relu'))\r\n",
        "model.add(layers.Dense(46,activation='softmax'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncA3h_5iLJNO"
      },
      "source": [
        "model.fit(partial_x_train, \r\n",
        "                  partial_y_train,\r\n",
        "                  epochs=20,\r\n",
        "                  batch_size=512,\r\n",
        "                  validation_data=(x_val,y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb2quXRWLOZU"
      },
      "source": [
        "검증 정확도의 최고 값은 약 69%로 10% 정도 감소했습니다. \r\n",
        "이런 손실의 원인 대부분은 많은 정보(클래스 46개의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다.\r\n",
        "이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0nSticlKtW1"
      },
      "source": [
        "## 3.5.9 정리 \r\n",
        "+ N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 Dense 층의 크기는 N이어야 합니다. \r\n",
        "+ 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 softmax 활성화 함수를 사용해야 합니다. \r\n",
        "+ 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다. \r\n",
        "+ 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다 \r\n",
        "  > 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 categorical_crossentropy 손실 함수를 사용합니다.\r\n",
        "  \r\n",
        "  > 레이블을 정수로 인코딩하고 spaese_categorical_crossentropy손실 함수를 사용합니다. \r\n",
        "+많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a3J1hs9M3x0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nn0OjsnKlJX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVPtWIYoJ8_2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaizLpSsJ9CV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ7sQ5fAJ9EF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0skrCBcsJ9Gu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fRwRrQJ9JA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}